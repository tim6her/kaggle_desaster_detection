{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Model Training\n\n## 1. Setting Up Spark Context"
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": "from pyspark import SparkContext, SparkConf\nfrom pyspark.sql import SparkSession"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n\nspark = SparkSession \\\n    .builder \\\n    .getOrCreate()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 2. Download data from Object Store"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Please enter value for IBM_API_KEY_ID: \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\nPlease enter value for IBM_OBJECT_STORE_BUCKET: \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\n"
                }
            ],
            "source": "import os\nimport getpass\n\ndef get_or_set_environment_variable(variable):\n    try:\n        var = os.environ[variable]\n    except KeyError:\n        var = getpass.getpass('Please enter value for {:}: '.format(variable))\n    \n    os.environ[variable] = var\n    return var\n\nibm_api_key_id = get_or_set_environment_variable('IBM_API_KEY_ID')\nibm_cloud_store_bucket = get_or_set_environment_variable('IBM_OBJECT_STORE_BUCKET')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 2.1 Load Training Data"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "{'train': ['desaster_detection_clean_train-0000.parquet'],\n 'test': ['desaster_detection_clean_test-0000.parquet'],\n 'label': ['desaster_detection_label-0000.parquet']}"
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": "def load_dataframe(files, **kargs):\n    dfs = []\n    for fn in files:\n        body = client.get_object(Bucket=ibm_cloud_store_bucket,\n                                 Key=fn)['Body']\n        if not hasattr(body, \"__iter__\"):\n            body.__iter__ = types.MethodType( __iter__, body )\n        \n        tfn = 'temp_{:}'.format(fn)\n        with open(tfn, 'wb') as temp:\n            temp.write(body.read())\n        dfs.append(spark.read.options(**kargs).parquet(tfn))\n    df = dfs.pop()\n    for other in dfs:\n        df = df.union(other)\n    return df\n\ndf_train = load_dataframe(files['train'])\ndf_label = load_dataframe(files['label'])"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 2.2 Load Model Definitions"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "{'LogisticRegression_count.ai.zip': 'spark',\n 'LogisticRegression_tfidf.ai.zip': 'spark',\n 'NaiveBayes_count.ai.zip': 'spark',\n 'NaiveBayes_tfidf.ai.zip': 'spark',\n 'Sequential_NN_w2v.ai.h5': 'keras'}"
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "['./temp_LogisticRegression_count.ai.zip',\n './temp_LogisticRegression_tfidf.ai.zip',\n './temp_NaiveBayes_count.ai.zip',\n './temp_NaiveBayes_tfidf.ai.zip',\n './temp_Sequential_NN_w2v.ai.h5']"
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "def download_model_files(files):\n    temp_files = []\n    for fn in files:\n        body = client.get_object(Bucket=ibm_cloud_store_bucket,\n                                 Key=fn)['Body']\n        if not hasattr(body, \"__iter__\"):\n            body.__iter__ = types.MethodType( __iter__, body )\n        \n        tfn = os.path.join(os.path.curdir, 'temp_{:}'.format(fn))\n        with open(tfn, 'wb') as temp:\n            temp.write(body.read())\n            \n        temp_files.append(tfn)\n    return temp_files\n\nmodel_temp_files = download_model_files(model_files.keys())\nmodel_temp_files"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "['./LogisticRegression_count.ai/',\n './LogisticRegression_tfidf.ai/',\n './NaiveBayes_count.ai/',\n './NaiveBayes_tfidf.ai/']"
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "import zipfile\n\ndef unzip_file(path):\n    with zipfile.ZipFile(path, 'r') as zip_ref:\n        zip_ref.extractall(os.curdir)\n        extracted = zip_ref.namelist()[0]\n    return os.path.join(os.curdir, extracted)\n\nextracted_models = [unzip_file(path) for path in model_temp_files[:-1]]\nextracted_models"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### 2.2.1 Logistic Regression"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "[LogisticRegression_6c76ceaefa53, LogisticRegression_05e1e1ba89f0]"
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from pyspark.ml.classification import LogisticRegression\n\nlrs = [LogisticRegression.load(t_file) for t_file in extracted_models[:2]]\nlrs"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### 2.2.2 Naive Bayes"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "[NaiveBayes_15f252f354da, NaiveBayes_f195de66bbed]"
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from pyspark.ml.classification import NaiveBayes\n\nnbs = [NaiveBayes.load(t_file) for t_file in extracted_models[2:4]]\nnbs"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### 2.2.3 Convolutional Neural Network"
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "'2.2.0-rc0'"
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "import tensorflow as tf\ntf.__version__"
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {
                "scrolled": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 82)                8282      \n_________________________________________________________________\nleaky_re_lu (LeakyReLU)      (None, 82)                0         \n_________________________________________________________________\ndropout (Dropout)            (None, 82)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 82)                6806      \n_________________________________________________________________\nleaky_re_lu_1 (LeakyReLU)    (None, 82)                0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 82)                0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 83        \n=================================================================\nTotal params: 15,171\nTrainable params: 15,171\nNon-trainable params: 0\n_________________________________________________________________\n"
                }
            ],
            "source": "from tensorflow import keras\n\nmodel = keras.models.load_model(model_temp_files[-1])\nmodel.summary()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 3. Training the models"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### 3.1 Transforming and Splitting Training Data"
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "+---+--------------------+--------------------+--------------------+--------------------+-----+\n| id|                text|      features_count|      features_tfidf|        features_w2v|label|\n+---+--------------------+--------------------+--------------------+--------------------+-----+\n|  1|Our Deeds are the...|(2266,[16,80,201,...|(2500,[26,166,336...|[-7.7565892466476...|    1|\n|  4|Forest fire near ...|(2266,[2,139,183,...|(2500,[191,974,20...|[-0.0055530799685...|    1|\n|  5|All residents ask...|(2266,[212,318,32...|(2500,[294,691,11...|[0.01664723102426...|    1|\n|  6|13,000 people rec...|(2266,[8,41,85,21...|(2500,[8,325,644,...|[-0.0023539206013...|    1|\n|  7|Just got sent thi...|(2266,[0,85,130,1...|(2500,[178,198,32...|[0.01491489600286...|    1|\n|  8|#RockyFire Update...|(2266,[2,41,85,21...|(2500,[191,325,64...|[-0.0123642495212...|    1|\n| 10|#flood #disaster ...|(2266,[15,21,57,1...|(2500,[353,356,64...|[0.00932735649985...|    1|\n| 13|I'm on top of the...|(2266,[2,25,187,1...|(2500,[15,191,187...|[-0.0102650801418...|    1|\n| 14|There's an emerge...|(2266,[20,198,212...|(2500,[36,99,699,...|[7.83063005656004...|    1|\n| 15|I'm afraid that t...|(2266,[19,239,322...|(2500,[649,1361,1...|[0.01196919969515...|    1|\n| 16|Three people died...|(2266,[8,109,166,...|(2500,[229,236,92...|[0.02737695723772...|    1|\n| 17|Haha South Tampa ...|(2266,[0,15,104,2...|(2500,[5,52,263,3...|[0.01289710899194...|    1|\n| 18|#raining #floodin...|(2266,[15,29,173,...|(2500,[52,605,113...|[0.01207213854003...|    1|\n| 19|#Flood in Bago My...|(2266,[15,731,774...|(2500,[1143,1277,...|[-0.0127024378627...|    1|\n| 20|Damage to school ...|(2266,[18,52,93,1...|(2500,[823,949,13...|[0.02633322446074...|    1|\n| 23|      What's up man?|   (2266,[53],[1.0])|(2500,[730],[4.21...|[0.04492759332060...|    0|\n| 24|       I love fruits|(2266,[37,1534],[...|(2500,[1240,2048]...|[0.01201907149516...|    0|\n| 25|    Summer is lovely|(2266,[272,1477],...|(2500,[1933,2228]...|[0.03516916371881...|    0|\n| 26|   My car is so fast|(2266,[52,515],[1...|(2500,[1763,2372]...|[0.02636489830911...|    0|\n| 28|What a goooooooaa...|        (2266,[],[])| (2500,[2136],[0.0])|[0.0,0.0,0.0,0.0,...|    0|\n+---+--------------------+--------------------+--------------------+--------------------+-----+\nonly showing top 20 rows\n\n"
                }
            ],
            "source": "import pyspark.sql.functions as sfun\n\ndf_train = df_train.join(df_label.select('id', sfun.col('target').alias('label')), on='id', how='inner')\ndf_train.show()"
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Training Dataset Count: 5355\nTest Dataset Count: 2258\n"
                }
            ],
            "source": "df_training, df_validation = df_train.randomSplit([0.7, 0.3], seed=42)\nprint(\"Training Dataset Count: \" + str(df_training.count()))\nprint(\"Test Dataset Count: \" + str(df_validation.count()))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### 3.2 Training Spark ML Models"
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Training LogisticRegression_6c76ceaefa53\nTraining LogisticRegression_05e1e1ba89f0\nTraining NaiveBayes_15f252f354da\nTraining NaiveBayes_f195de66bbed\n"
                },
                {
                    "data": {
                        "text/plain": "[LogisticRegressionModel: uid = LogisticRegression_6c76ceaefa53, numClasses = 2, numFeatures = 2266,\n LogisticRegressionModel: uid = LogisticRegression_05e1e1ba89f0, numClasses = 2, numFeatures = 2500,\n NaiveBayes_15f252f354da,\n NaiveBayes_f195de66bbed]"
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "spark_models = lrs + nbs\n\ndef training(model):\n    print('Training', model)\n    return model.fit(df_training)\n\ntrained = [training(model) for model in spark_models]\ntrained"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### 3.3 Training Keras Model"
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "(5355, 100)"
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "import numpy as np\nX = np.array(df_training.select('features_w2v').collect())\nX = X.reshape(-1, 100)\n\ny = np.array(df_training.select('label').collect())\ny = y.reshape(-1,)\n\nX.shape"
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Epoch 1/50\n35/35 [==============================] - 1s 18ms/step - loss: 0.6705 - accuracy: 0.6179 - val_loss: 0.6563 - val_accuracy: 0.6116\nEpoch 2/50\n35/35 [==============================] - 0s 14ms/step - loss: 0.6320 - accuracy: 0.6592 - val_loss: 0.6177 - val_accuracy: 0.6984\nEpoch 3/50\n35/35 [==============================] - 0s 13ms/step - loss: 0.6178 - accuracy: 0.6718 - val_loss: 0.5960 - val_accuracy: 0.7106\nEpoch 4/50\n35/35 [==============================] - 0s 13ms/step - loss: 0.6056 - accuracy: 0.6837 - val_loss: 0.5885 - val_accuracy: 0.6993\nEpoch 5/50\n35/35 [==============================] - 0s 11ms/step - loss: 0.6025 - accuracy: 0.6772 - val_loss: 0.5792 - val_accuracy: 0.7143\nEpoch 6/50\n35/35 [==============================] - 0s 13ms/step - loss: 0.5984 - accuracy: 0.6839 - val_loss: 0.5761 - val_accuracy: 0.7152\nEpoch 7/50\n35/35 [==============================] - 0s 12ms/step - loss: 0.5960 - accuracy: 0.6879 - val_loss: 0.5800 - val_accuracy: 0.7171\nEpoch 8/50\n35/35 [==============================] - 0s 12ms/step - loss: 0.5920 - accuracy: 0.6879 - val_loss: 0.5781 - val_accuracy: 0.7171\nEpoch 9/50\n35/35 [==============================] - 0s 12ms/step - loss: 0.5922 - accuracy: 0.6881 - val_loss: 0.5800 - val_accuracy: 0.7134\nEpoch 10/50\n35/35 [==============================] - 0s 11ms/step - loss: 0.5914 - accuracy: 0.6879 - val_loss: 0.5734 - val_accuracy: 0.7236\nEpoch 11/50\n35/35 [==============================] - 0s 12ms/step - loss: 0.5884 - accuracy: 0.6905 - val_loss: 0.5733 - val_accuracy: 0.7274\nEpoch 12/50\n35/35 [==============================] - 0s 12ms/step - loss: 0.5898 - accuracy: 0.6900 - val_loss: 0.5736 - val_accuracy: 0.7302\nEpoch 13/50\n35/35 [==============================] - 0s 12ms/step - loss: 0.5843 - accuracy: 0.6909 - val_loss: 0.5731 - val_accuracy: 0.7292\nEpoch 14/50\n35/35 [==============================] - 0s 12ms/step - loss: 0.5846 - accuracy: 0.6928 - val_loss: 0.5744 - val_accuracy: 0.7274\nEpoch 15/50\n35/35 [==============================] - 0s 12ms/step - loss: 0.5843 - accuracy: 0.6986 - val_loss: 0.5739 - val_accuracy: 0.7246\nEpoch 16/50\n35/35 [==============================] - 0s 12ms/step - loss: 0.5806 - accuracy: 0.6958 - val_loss: 0.5711 - val_accuracy: 0.7274\nEpoch 17/50\n35/35 [==============================] - 0s 12ms/step - loss: 0.5794 - accuracy: 0.6996 - val_loss: 0.5700 - val_accuracy: 0.7292\nEpoch 18/50\n35/35 [==============================] - 0s 12ms/step - loss: 0.5790 - accuracy: 0.6965 - val_loss: 0.5732 - val_accuracy: 0.7274\nEpoch 19/50\n35/35 [==============================] - 0s 12ms/step - loss: 0.5782 - accuracy: 0.7000 - val_loss: 0.5683 - val_accuracy: 0.7246\nEpoch 20/50\n35/35 [==============================] - 0s 12ms/step - loss: 0.5757 - accuracy: 0.7021 - val_loss: 0.5740 - val_accuracy: 0.7274\nEpoch 21/50\n35/35 [==============================] - 0s 12ms/step - loss: 0.5741 - accuracy: 0.7038 - val_loss: 0.5681 - val_accuracy: 0.7264\nEpoch 22/50\n35/35 [==============================] - 0s 12ms/step - loss: 0.5721 - accuracy: 0.7087 - val_loss: 0.5635 - val_accuracy: 0.7283\nEpoch 23/50\n35/35 [==============================] - 0s 11ms/step - loss: 0.5695 - accuracy: 0.7094 - val_loss: 0.5654 - val_accuracy: 0.7292\nEpoch 24/50\n35/35 [==============================] - 0s 11ms/step - loss: 0.5774 - accuracy: 0.7031 - val_loss: 0.5767 - val_accuracy: 0.7227\nEpoch 25/50\n35/35 [==============================] - 0s 12ms/step - loss: 0.5721 - accuracy: 0.7108 - val_loss: 0.5673 - val_accuracy: 0.7311\nEpoch 26/50\n35/35 [==============================] - 0s 12ms/step - loss: 0.5675 - accuracy: 0.7150 - val_loss: 0.5662 - val_accuracy: 0.7264\nEpoch 27/50\n35/35 [==============================] - 0s 12ms/step - loss: 0.5680 - accuracy: 0.7045 - val_loss: 0.5672 - val_accuracy: 0.7292\nEpoch 28/50\n35/35 [==============================] - 0s 11ms/step - loss: 0.5644 - accuracy: 0.7192 - val_loss: 0.5643 - val_accuracy: 0.7292\nEpoch 29/50\n35/35 [==============================] - 0s 11ms/step - loss: 0.5666 - accuracy: 0.7124 - val_loss: 0.5650 - val_accuracy: 0.7320\nEpoch 30/50\n35/35 [==============================] - 0s 12ms/step - loss: 0.5639 - accuracy: 0.7129 - val_loss: 0.5676 - val_accuracy: 0.7227\nEpoch 31/50\n35/35 [==============================] - 0s 11ms/step - loss: 0.5632 - accuracy: 0.7136 - val_loss: 0.5595 - val_accuracy: 0.7208\nEpoch 32/50\n35/35 [==============================] - 0s 12ms/step - loss: 0.5606 - accuracy: 0.7192 - val_loss: 0.5665 - val_accuracy: 0.7218\nEpoch 33/50\n35/35 [==============================] - 0s 11ms/step - loss: 0.5582 - accuracy: 0.7176 - val_loss: 0.5675 - val_accuracy: 0.7208\nEpoch 34/50\n35/35 [==============================] - 0s 12ms/step - loss: 0.5598 - accuracy: 0.7145 - val_loss: 0.5602 - val_accuracy: 0.7227\nEpoch 35/50\n35/35 [==============================] - 0s 12ms/step - loss: 0.5549 - accuracy: 0.7232 - val_loss: 0.5602 - val_accuracy: 0.7311\nEpoch 36/50\n35/35 [==============================] - 0s 12ms/step - loss: 0.5553 - accuracy: 0.7241 - val_loss: 0.5607 - val_accuracy: 0.7320\nEpoch 37/50\n35/35 [==============================] - 0s 13ms/step - loss: 0.5541 - accuracy: 0.7239 - val_loss: 0.5634 - val_accuracy: 0.7358\nEpoch 38/50\n35/35 [==============================] - 0s 11ms/step - loss: 0.5494 - accuracy: 0.7260 - val_loss: 0.5598 - val_accuracy: 0.7208\nEpoch 39/50\n35/35 [==============================] - 0s 12ms/step - loss: 0.5531 - accuracy: 0.7215 - val_loss: 0.5644 - val_accuracy: 0.7274\nEpoch 40/50\n35/35 [==============================] - 0s 12ms/step - loss: 0.5571 - accuracy: 0.7213 - val_loss: 0.5576 - val_accuracy: 0.7292\nEpoch 41/50\n35/35 [==============================] - 0s 13ms/step - loss: 0.5542 - accuracy: 0.7171 - val_loss: 0.5557 - val_accuracy: 0.7311\nEpoch 42/50\n35/35 [==============================] - 0s 13ms/step - loss: 0.5491 - accuracy: 0.7241 - val_loss: 0.5539 - val_accuracy: 0.7311\nEpoch 43/50\n35/35 [==============================] - 0s 12ms/step - loss: 0.5476 - accuracy: 0.7288 - val_loss: 0.5496 - val_accuracy: 0.7339\nEpoch 44/50\n35/35 [==============================] - 0s 12ms/step - loss: 0.5475 - accuracy: 0.7288 - val_loss: 0.5568 - val_accuracy: 0.7274\nEpoch 45/50\n35/35 [==============================] - 0s 12ms/step - loss: 0.5456 - accuracy: 0.7306 - val_loss: 0.5527 - val_accuracy: 0.7255\nEpoch 46/50\n35/35 [==============================] - 0s 12ms/step - loss: 0.5486 - accuracy: 0.7257 - val_loss: 0.5554 - val_accuracy: 0.7283\nEpoch 47/50\n35/35 [==============================] - 0s 12ms/step - loss: 0.5422 - accuracy: 0.7341 - val_loss: 0.5544 - val_accuracy: 0.7302\nEpoch 48/50\n35/35 [==============================] - 0s 13ms/step - loss: 0.5410 - accuracy: 0.7281 - val_loss: 0.5527 - val_accuracy: 0.7302\nEpoch 49/50\n35/35 [==============================] - 0s 12ms/step - loss: 0.5431 - accuracy: 0.7292 - val_loss: 0.5496 - val_accuracy: 0.7348\nEpoch 50/50\n35/35 [==============================] - 0s 12ms/step - loss: 0.5418 - accuracy: 0.7332 - val_loss: 0.5521 - val_accuracy: 0.7274\n"
                }
            ],
            "source": "history = model.fit(X, y,\n                    batch_size=124, epochs=50, validation_split=0.2)"
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": "import plotly.io as pio\npio.renderers.default = 'notebook_connected'"
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": "<div>\n        \n        \n            <div id=\"ceb2294e-8e26-442d-92ed-ca8fd50abae2\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    \n                if (document.getElementById(\"ceb2294e-8e26-442d-92ed-ca8fd50abae2\")) {\n                    Plotly.newPlot(\n                        'ceb2294e-8e26-442d-92ed-ca8fd50abae2',\n                        [{\"hovertemplate\": \"variable=loss<br>epoche=%{x}<br>value=%{y}<extra></extra>\", \"legendgroup\": \"loss\", \"line\": {\"color\": \"#636efa\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"loss\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"xaxis\": \"x\", \"y\": [0.6704714894294739, 0.6320063471794128, 0.6178480386734009, 0.6055793166160583, 0.6025254130363464, 0.598386287689209, 0.5959584712982178, 0.5919774174690247, 0.5921578407287598, 0.5913613438606262, 0.5883632898330688, 0.5898429751396179, 0.5843487977981567, 0.5845858454704285, 0.5842554569244385, 0.5806030631065369, 0.5794032216072083, 0.5790013074874878, 0.578230082988739, 0.5756860971450806, 0.5741307139396667, 0.5721299052238464, 0.5695206522941589, 0.5773956775665283, 0.5721079707145691, 0.567464292049408, 0.5679912567138672, 0.5644213557243347, 0.5666413903236389, 0.5638831853866577, 0.563199520111084, 0.5606061220169067, 0.5582330822944641, 0.5598121881484985, 0.5549042224884033, 0.55534428358078, 0.5540584921836853, 0.5493664741516113, 0.5530684590339661, 0.5571314692497253, 0.554188072681427, 0.5491102337837219, 0.5476346611976624, 0.5474935173988342, 0.5456342697143555, 0.5485988855361938, 0.5421739220619202, 0.5410069227218628, 0.5430763959884644, 0.5417984127998352], \"yaxis\": \"y\"}, {\"hovertemplate\": \"variable=accuracy<br>epoche=%{x}<br>value=%{y}<extra></extra>\", \"legendgroup\": \"accuracy\", \"line\": {\"color\": \"#EF553B\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"accuracy\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"xaxis\": \"x\", \"y\": [0.6178804636001587, 0.6591970324516296, 0.6718020439147949, 0.6837068200111389, 0.6771708726882935, 0.6839402318000793, 0.6879084706306458, 0.6879084706306458, 0.688141942024231, 0.6879084706306458, 0.6904761791229248, 0.690009355545044, 0.6909430623054504, 0.6928104758262634, 0.6986461281776428, 0.6958450078964233, 0.6995798349380493, 0.6965453028678894, 0.7000466585159302, 0.7021475434303284, 0.7037814855575562, 0.7086834907531738, 0.7093837261199951, 0.7030812501907349, 0.7107843160629272, 0.7149859666824341, 0.7044817805290222, 0.7191876769065857, 0.7124183177947998, 0.7128851413726807, 0.7135854363441467, 0.7191876769065857, 0.7175536751747131, 0.7145191431045532, 0.7231559157371521, 0.7240896224975586, 0.7238562107086182, 0.7259570360183716, 0.7215219140052795, 0.7212885022163391, 0.7170868515968323, 0.7240896224975586, 0.7287581562995911, 0.7287581562995911, 0.730625569820404, 0.7257236242294312, 0.7341269850730896, 0.728057861328125, 0.7292250394821167, 0.7331932783126831], \"yaxis\": \"y\"}, {\"hovertemplate\": \"variable=val_loss<br>epoche=%{x}<br>value=%{y}<extra></extra>\", \"legendgroup\": \"val_loss\", \"line\": {\"color\": \"#00cc96\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"val_loss\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"xaxis\": \"x\", \"y\": [0.6563059091567993, 0.617653489112854, 0.5959562659263611, 0.588454008102417, 0.5792073011398315, 0.5760806202888489, 0.579973042011261, 0.5780544281005859, 0.5799883008003235, 0.5733948349952698, 0.5732882022857666, 0.573588490486145, 0.5730981230735779, 0.5743992328643799, 0.5738531351089478, 0.5711241960525513, 0.5700053572654724, 0.5732277631759644, 0.5683090686798096, 0.5740317702293396, 0.5681421756744385, 0.5634708404541016, 0.5653977990150452, 0.5767171382904053, 0.5672610402107239, 0.5662454962730408, 0.5672156810760498, 0.5643051266670227, 0.5650173425674438, 0.5676190853118896, 0.5595245957374573, 0.5665134787559509, 0.5674648880958557, 0.5601696372032166, 0.5602494478225708, 0.5607126355171204, 0.5633788108825684, 0.5597701668739319, 0.5644269585609436, 0.5575798749923706, 0.5556721091270447, 0.5539369583129883, 0.5496024489402771, 0.556793749332428, 0.5526621341705322, 0.555392324924469, 0.5543963313102722, 0.552748441696167, 0.5495532751083374, 0.5521275997161865], \"yaxis\": \"y\"}, {\"hovertemplate\": \"variable=val_accuracy<br>epoche=%{x}<br>value=%{y}<extra></extra>\", \"legendgroup\": \"val_accuracy\", \"line\": {\"color\": \"#ab63fa\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"val_accuracy\", \"orientation\": \"v\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"xaxis\": \"x\", \"y\": [0.6115779876708984, 0.6984127163887024, 0.7105509042739868, 0.6993464231491089, 0.7142857313156128, 0.7152194380760193, 0.7170868515968323, 0.7170868515968323, 0.7133520245552063, 0.7236227989196777, 0.7273576259613037, 0.7301587462425232, 0.7292250394821167, 0.7273576259613037, 0.7245565056800842, 0.7273576259613037, 0.7292250394821167, 0.7273576259613037, 0.7245565056800842, 0.7273576259613037, 0.7264239192008972, 0.7282913327217102, 0.7292250394821167, 0.7226890921592712, 0.7310924530029297, 0.7264239192008972, 0.7292250394821167, 0.7292250394821167, 0.7320261597633362, 0.7226890921592712, 0.7208216786384583, 0.7217553853988647, 0.7208216786384583, 0.7226890921592712, 0.7310924530029297, 0.7320261597633362, 0.7357609868049622, 0.7208216786384583, 0.7273576259613037, 0.7292250394821167, 0.7310924530029297, 0.7310924530029297, 0.7338935732841492, 0.7273576259613037, 0.7254902124404907, 0.7282913327217102, 0.7301587462425232, 0.7301587462425232, 0.7348272800445557, 0.7273576259613037], \"yaxis\": \"y\"}],\n                        {\"legend\": {\"title\": {\"text\": \"variable\"}, \"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"epoche\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"value\"}}},\n                        {\"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('ceb2294e-8e26-442d-92ed-ca8fd50abae2');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": "import plotly.express as px\nimport pandas as pd\n\nloss_values = history.history['loss']\nacc_values = history.history['accuracy']\nhistory.history['epoche'] = range(1, len(loss_values)+1)\n\nfig = px.line(pd.DataFrame(history.history),\n              x='epoche', y=['loss', 'accuracy', 'val_loss', 'val_accuracy'])\nfig.show()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 4. Serializing Trained Models"
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": "!rm -rf *_*.ai"
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "['LogisticRegressionModel_count_trained.ai.zip',\n 'LogisticRegressionModel_tfidf_trained.ai.zip',\n 'NaiveBayes_15f252f354da_count_trained.ai.zip',\n 'NaiveBayes_f195de66bbed_tfidf_trained.ai.zip']"
                    },
                    "execution_count": 21,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "import os\nimport shutil\n\nspark_models = lrs + nbs\n\ndef serialize_spark_model(model, name, feature):\n    export_path = '{name:}_{feature:}_trained.ai'.format(name=name, feature=feature)\n    model.save(export_path)\n    return shutil.make_archive(base_name=export_path,\n                               format='zip', base_dir=export_path)\n\nspark_paths = [serialize_spark_model(model, str(model).split(':')[0], feature)\n                for model, feature in zip(trained, ['count', 'tfidf'] * 2)]\nspark_paths"
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "'Sequential_NN_w2v_trained.ai.h5'"
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "def serialize_keras_model(model, name, feature):\n    export_path = '{name:}_{feature:}_trained.ai.h5'.format(name=name, feature=feature)\n    model.save(export_path)\n    return export_path\n\nkeras_path = serialize_keras_model(model, 'Sequential_NN', 'w2v')\nkeras_path"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 5. Serializing the Validation dataframe in Parquet Format"
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": "!rm -r ./desaster_detection_*"
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "['./desaster_detection_validation_validation']"
                    },
                    "execution_count": 24,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "import glob\n\ntemp_parquet_file = os.path.join(os.path.curdir,\n                                 'desaster_detection_validation_{}')\ndf_validation.write.parquet(temp_parquet_file.format('validation'), mode='overwrite')\n\nglob.glob(temp_parquet_file.format('*'))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 6. Uploading the Files to Object Cloud"
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "{'LogisticRegressionModel_count_trained.ai.zip': 'spark',\n 'LogisticRegressionModel_tfidf_trained.ai.zip': 'spark',\n 'NaiveBayes_15f252f354da_count_trained.ai.zip': 'spark',\n 'NaiveBayes_f195de66bbed_tfidf_trained.ai.zip': 'spark',\n 'Sequential_NN_w2v_trained.ai.h5': 'keras'}"
                    },
                    "execution_count": 25,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "def upload_model(client, path, model_key):\n    with open(path, 'rb') as modelF:\n        client.put_object(Bucket=ibm_cloud_store_bucket,\n                          Body=modelF,\n                          Key=model_key\n                         )\n    return model_key\n\nclient = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id=ibm_api_key_id,\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n\nmodels = {upload_model(client, path, model_key=path): 'spark'\n          for path in spark_paths}\nmodels[upload_model(client, keras_path, model_key = keras_path)] = 'keras'\n\nmodels"
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "{'ResponseMetadata': {'RequestId': '45d8c6a3-8ea4-40b0-82b0-a895f0d5e89b',\n  'HostId': '',\n  'HTTPStatusCode': 200,\n  'HTTPHeaders': {'date': 'Sun, 31 Jan 2021 16:21:26 GMT',\n   'x-clv-request-id': '45d8c6a3-8ea4-40b0-82b0-a895f0d5e89b',\n   'server': 'Cleversafe',\n   'x-clv-s3-version': '2.5',\n   'x-amz-request-id': '45d8c6a3-8ea4-40b0-82b0-a895f0d5e89b',\n   'etag': '\"9c0d62541008f2873813d5f2c4b00ac0\"',\n   'content-length': '0'},\n  'RetryAttempts': 0},\n 'ETag': '\"9c0d62541008f2873813d5f2c4b00ac0\"'}"
                    },
                    "execution_count": 26,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "import json\n\nclient.put_object(Bucket=ibm_cloud_store_bucket,\n                  Body=json.dumps(models),\n                  Key='model_train_files.json')"
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "{'validation': ['desaster_detection_validation_validation-0000.parquet']}\n"
                }
            ],
            "source": "def upload_parquet(client, path):\n    parts = glob.glob(os.path.join(path, '*.parquet'))\n    parquets = ['{:s}-{:04d}.parquet'.format(os.path.split(path)[-1], i)\n                for i in range(len(parts))]\n    for part, parquet in zip(parts, parquets):\n        with open(part, 'rb') as parquetF:\n            client.put_object(Bucket=ibm_cloud_store_bucket,\n                          Body=parquetF,\n                          Key=parquet\n                         )\n    return parquets\n\nclient = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id=ibm_api_key_id,\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n\n\nparquets = {}\nfor dataset in ('validation',):\n    parquets[dataset] = upload_parquet(client, temp_parquet_file.format(dataset))\n\nprint(parquets)"
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "{'ResponseMetadata': {'RequestId': '1967474a-f7a8-4fda-85b3-e9997551cd7e',\n  'HostId': '',\n  'HTTPStatusCode': 200,\n  'HTTPHeaders': {'date': 'Sun, 31 Jan 2021 16:21:27 GMT',\n   'x-clv-request-id': '1967474a-f7a8-4fda-85b3-e9997551cd7e',\n   'server': 'Cleversafe',\n   'x-clv-s3-version': '2.5',\n   'x-amz-request-id': '1967474a-f7a8-4fda-85b3-e9997551cd7e',\n   'etag': '\"b0bf149ce6f4f580db8b8e2ddfb57f55\"',\n   'content-length': '0'},\n  'RetryAttempts': 0},\n 'ETag': '\"b0bf149ce6f4f580db8b8e2ddfb57f55\"'}"
                    },
                    "execution_count": 28,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "import json\n\n\nparquets.update(files)\nclient.put_object(Bucket=ibm_cloud_store_bucket,\n                  Body=json.dumps(parquets),\n                  Key='validation_parquet_files.json')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.7",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}